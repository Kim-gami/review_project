# -*- coding: utf-8 -*-
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    TimeoutException, ElementClickInterceptedException,
    StaleElementReferenceException, NoSuchElementException
)
import os, re, time
from datetime import datetime

# ğŸ”— ì •ìë™ ì‹ë‹¹ ê²€ìƒ‰ URL
SEARCH_URL = "https://map.naver.com/p/search/%EC%A0%95%EC%9E%90%EB%8F%99%20%EC%8B%9D%EB%8B%B9?c=14.00,0,0,0,dh"
SAVE_DIR = "saved_pages"

WAIT_LONG = 20
WAIT_SHORT = 8

def make_driver():
    opts = webdriver.ChromeOptions()
    opts.add_experimental_option("detach", True)   # ìŠ¤í¬ë¦½íŠ¸ ëë‚˜ë„ ì°½ ìœ ì§€
    driver = webdriver.Chrome(options=opts)
    driver.set_window_size(1300, 950)
    return driver

def wwait(drv, t=WAIT_LONG, poll=0.2):
    return WebDriverWait(drv, t, poll_frequency=poll)

def click_with_retry(drv, by, sel, tries=4, pre_sleep=0.2, post_sleep=0.35, timeout=WAIT_SHORT):
    last_err = None
    for attempt in range(1, tries+1):
        try:
            if pre_sleep: time.sleep(pre_sleep)
            w = wwait(drv, timeout)
            el = w.until(EC.presence_of_element_located((by, sel)))
            el = w.until(EC.visibility_of_element_located((by, sel)))
            drv.execute_script("arguments[0].scrollIntoView({block:'center'});", el)
            w.until(EC.element_to_be_clickable((by, sel)))
            try:
                ActionChains(drv).move_to_element(el).pause(0.05).click(el).perform()
            except (ElementClickInterceptedException, StaleElementReferenceException):
                drv.execute_script("arguments[0].click();", el)
            if post_sleep: time.sleep(post_sleep)
            return el
        except Exception as e:
            last_err = e
            time.sleep(0.5 + 0.25*attempt)
    raise TimeoutException(f"click_with_retry ì‹¤íŒ¨: {sel} // {last_err}")

def to_search_iframe(drv):
    drv.switch_to.default_content()
    wwait(drv).until(EC.presence_of_element_located((By.ID, "searchIframe")))
    drv.switch_to.frame(drv.find_element(By.ID, "searchIframe"))

def to_entry_iframe(drv):
    drv.switch_to.default_content()
    wwait(drv).until(EC.presence_of_element_located((By.ID, "entryIframe")))
    drv.switch_to.frame(drv.find_element(By.ID, "entryIframe"))
    time.sleep(0.5)

def wait_entry_loaded(drv, timeout=WAIT_LONG):
    w = wwait(drv, timeout)
    try:
        w.until(EC.presence_of_element_located((By.XPATH, "//section[contains(@class,'place_section')]")))
    except TimeoutException:
        time.sleep(0.8)

def wait_reviews_ready(drv, timeout=WAIT_SHORT):
    w = wwait(drv, timeout)
    try:
        w.until(lambda d: d.execute_script("return document.readyState") == "complete")
    except Exception:
        pass
    time.sleep(0.6)

def save_html(drv, label="page"):
    os.makedirs(SAVE_DIR, exist_ok=True)
    ts = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    safe_label = re.sub(r"[^0-9A-Za-zê°€-í£._-]", "_", label)[:80] or "page"
    path = os.path.join(SAVE_DIR, f"{ts}_{safe_label}.html")
    with open(path, "w", encoding="utf-8") as f:
        f.write(drv.page_source)
    print(f"[SAVE] {path}")
    return path

def wait_review_container(drv, timeout=20):
    candidates = [
        (By.CSS_SELECTOR, "#_review_list"),
        (By.CSS_SELECTOR, "div[id$='_review_list']"),
        (By.CSS_SELECTOR, "section[class*='place_section'][data-tab='review']"),
        (By.CSS_SELECTOR, "div.place_section_content"),
    ]
    w = wwait(drv, timeout, poll=0.2)
    for by, sel in candidates:
        try:
            el = w.until(EC.presence_of_element_located((by, sel)))
            drv.execute_script("arguments[0].scrollIntoView({block:'center'});", el)
            return el
        except Exception:
            continue
    raise TimeoutException("ë¦¬ë·° ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

def save_review_section_html(drv, label="review_section"):
    os.makedirs(SAVE_DIR, exist_ok=True)
    to_entry_iframe(drv)
    el = wait_review_container(drv, timeout=20)
    html = el.get_attribute("outerHTML")
    ts = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    safe_label = re.sub(r"[^0-9A-Za-zê°€-í£._-]", "_", label)[:80] or "review_section"
    path = os.path.join(SAVE_DIR, f"{ts}_{safe_label}.html")
    with open(path, "w", encoding="utf-8") as f:
        f.write(html)
    print(f"[SAVE] ë¦¬ë·° ì„¹ì…˜ â†’ {path}")
    return path

# --------- ì¶”ê°€: ê²€ìƒ‰ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë‹¤ê±´ ë°˜ë³µì„ ìœ„í•œ í—¬í¼ë“¤ ---------
def list_search_items(drv, timeout=WAIT_LONG):
    """ê²€ìƒ‰ iframeì—ì„œ ê°€ê²Œëª… spanë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜(í…ìŠ¤íŠ¸, locator íŠœí”Œ)."""
    to_search_iframe(drv)
    w = wwait(drv, timeout)
    # ê°€ê²Œëª… ìŠ¤íŒ¬(ë¦¬ìŠ¤íŠ¸ ì˜ì—­). í´ë˜ìŠ¤ëŠ” ë³€ê²½ë  ìˆ˜ ìˆì–´ ê°€ì¥ ë³´í¸ íŒ¨í„´ ì‚¬ìš©
    w.until(EC.presence_of_all_elements_located((By.XPATH, "//span[contains(@class,'TYaxT')]")))
    spans = drv.find_elements(By.XPATH, "//span[contains(@class,'TYaxT')]")
    items = []
    for idx, el in enumerate(spans):
        try:
            name = el.text.strip()
            if not name:
                continue
            # ì¸ë±ìŠ¤ ê¸°ë°˜ ì¬íƒìƒ‰ ê°€ëŠ¥í•œ XPATH
            xp = f"(//span[contains(@class,'TYaxT')])[{idx+1}]"
            items.append((name, (By.XPATH, xp)))
        except Exception:
            continue
    if not items:
        raise TimeoutException("ê²€ìƒ‰ ê²°ê³¼ ì•„ì´í…œì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return items

def open_reviews_tab_and_sort(drv, tries=4, sort_latest=True):
    """ìƒì„¸ iframeì—ì„œ ë¦¬ë·° íƒ­ í´ë¦­, (ì˜µì…˜) ìµœì‹ ìˆœ ì„ íƒ."""
    to_entry_iframe(drv)
    wait_entry_loaded(drv)

    # ë¦¬ë·° íƒ­
    print("[CLICK] ë¦¬ë·° íƒ­")
    click_with_retry(
        drv, By.XPATH,
        "//span[contains(@class,'veBoZ') and normalize-space()='ë¦¬ë·°']",
        tries=max(tries, 3), pre_sleep=0.4, post_sleep=0.8, timeout=WAIT_LONG
    )
    wait_reviews_ready(drv)

    # ìµœì‹ ìˆœ ì •ë ¬(ì˜µì…˜)
    if sort_latest:
        # ë“œë¡­ë‹¤ìš´ì´ ì´ë¯¸ ì—´ë ¤ìˆëŠ” ê²½ìš°/ì•„ë‹Œ ê²½ìš° ëª¨ë‘ ì»¤ë²„: 'ìµœì‹ ìˆœ' ì˜µì…˜ ìì²´ë¥¼ ì§ì ‘ í´ë¦­
        print("[CLICK] ë¦¬ë·° ì •ë ¬(ìµœì‹ ìˆœ)")
        try:
            click_with_retry(
                drv, By.XPATH,
                "//a[@role='option' and contains(@class,'place_btn_option') and normalize-space()='ìµœì‹ ìˆœ']",
                tries=3, pre_sleep=0.3, post_sleep=0.6, timeout=WAIT_SHORT
            )
        except Exception:
            # ë“œë¡­ë‹¤ìš´ í† ê¸€ ëˆ„ë¥´ê³  ë‹¤ì‹œ ì‹œë„
            try:
                click_with_retry(
                    drv, By.XPATH,
                    "//button[contains(@class,'place_section_content')]//span[contains(text(),'ì •ë ¬')]",
                    tries=2, pre_sleep=0.2, post_sleep=0.4, timeout=WAIT_SHORT
                )
                click_with_retry(
                    drv, By.XPATH,
                    "//a[@role='option' and contains(@class,'place_btn_option') and normalize-space()='ìµœì‹ ìˆœ']",
                    tries=3, pre_sleep=0.2, post_sleep=0.6, timeout=WAIT_SHORT
                )
            except Exception:
                print("[WARN] ìµœì‹ ìˆœ ì„ íƒ ì‹¤íŒ¨ â€” ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
    return True

def expand_all_reviews(drv, max_clicks=300, scroll_step=500, pause=0.25):
    """
    ìƒì„¸ iframeì—ì„œ ë¦¬ë·° ë³¸ë¬¸ 'ë”ë³´ê¸°(rvshowmore)'ë§Œ ëª¨ë‘ í¼ì¹¨.
    í´ë¦­í•œ ë²„íŠ¼ì€ ì¦‰ì‹œ DOMì—ì„œ ì œê±°í•´ ì¬í´ë¦­ì„ ë°©ì§€í•œë‹¤.
    """
    to_entry_iframe(drv)
    total_clicked = 0
    idle_rounds = 0  # ìƒˆ ë²„íŠ¼ì„ ëª» ì°¾ì€ ë¼ìš´ë“œ ìˆ˜(ì¢…ë£Œ ì¡°ê±´)

    while total_clicked < max_clicks and idle_rounds < 10:
        clicked_this_round = 0

        # ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ê¸°ì¤€ìœ¼ë¡œë§Œ íƒìƒ‰(ì‚¬ì§„ ë”ë³´ê¸° ë“± ì˜¤í´ë¦­ ë°©ì§€)
        containers = drv.find_elements(By.CSS_SELECTOR, "#_review_list, div[id$='_review_list']")
        scope = containers[0] if containers else drv

        # rvshowmoreë§Œ ëŒ€ìƒìœ¼ë¡œ (rvshowless/ì ‘ê¸° ì œì™¸)
        btns = scope.find_elements(By.CSS_SELECTOR, "a[data-pui-click-code='rvshowmore']")
        for b in btns:
            try:
                if not b.is_displayed():
                    continue
                # í˜¹ì‹œ í…ìŠ¤íŠ¸ê°€ 'ì ‘ê¸°'ë¡œ ë°”ë€ í† ê¸€í˜•ì´ë¼ë©´ íŒ¨ìŠ¤
                txt = (b.text or "").strip()
                if "ì ‘ê¸°" in txt:
                    continue

                # í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ ìŠ¤í¬ë¡¤
                drv.execute_script("arguments[0].scrollIntoView({block:'center'});", b)
                time.sleep(0.05)
                try:
                    ActionChains(drv).move_to_element(b).pause(0.02).click(b).perform()
                except (ElementClickInterceptedException, StaleElementReferenceException):
                    drv.execute_script("arguments[0].click();", b)

                # í´ë¦­ ì§í›„ ê°™ì€ ë²„íŠ¼ì„ ë‹¤ì‹œ ëª» ëˆ„ë¥´ê²Œ DOMì—ì„œ ì œê±°(ë˜ëŠ” í”Œë˜ê·¸)
                try:
                    drv.execute_script("""
                        if (arguments[0]) {
                            arguments[0].setAttribute('data-expanded-once','1');
                            arguments[0].parentNode && arguments[0].parentNode.removeChild(arguments[0]);
                        }
                    """, b)
                except Exception:
                    pass

                total_clicked += 1
                clicked_this_round += 1
                time.sleep(0.12)

                if total_clicked >= max_clicks:
                    break
            except Exception:
                continue

        if clicked_this_round == 0:
            idle_rounds += 1
            # ë”ë³´ê¸° ë²„íŠ¼ì´ ì˜ ì•ˆ ì¡íˆë©´ ì¡°ê¸ˆì”© ë‚´ë ¤ê°€ë©° íƒìƒ‰
            drv.execute_script(f"window.scrollBy(0, {scroll_step});")
            time.sleep(pause)
        else:
            idle_rounds = 0  # ìƒˆë¡œ í¼ì¹œ ê²Œ ìˆìœ¼ë©´ ì¹´ìš´í„° ì´ˆê¸°í™”

    print(f"[INFO] ë¦¬ë·° ë”ë³´ê¸° í¼ì¹¨ ì™„ë£Œ: {total_clicked}íšŒ, idle_rounds={idle_rounds}")


def run_crawl(max_places=10, sort_latest=True, expand_more=True):
    drv = make_driver()
    drv.get(SEARCH_URL)

    # ê²€ìƒ‰ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
    items = list_search_items(drv)
    print(f"[INFO] ê²€ìƒ‰ ê²°ê³¼ {len(items)}ê°œ ë°œê²¬. ìƒìœ„ {min(max_places, len(items))}ê°œ ì²˜ë¦¬.")

    processed = 0
    for idx, (name, locator) in enumerate(items, start=1):
        if processed >= max_places:
            break

        # ë™ì¼ ì¸ë±ìŠ¤ë¡œ ë§¤ë²ˆ ì¬íƒìƒ‰(iframe ìƒíƒœ ì´ˆê¸°í™”)
        to_search_iframe(drv)
        print(f"\n[CLICK] ({idx}) ê°€ê²Œ ì„ íƒ: {name}")
        try:
            # í´ë¦­ ì‹œ ìƒì„¸ iframeì´ ê°±ì‹ ë¨
            click_with_retry(drv, locator[0], locator[1], tries=4, pre_sleep=0.2, post_sleep=0.6, timeout=WAIT_LONG)
        except Exception as e:
            print(f"[WARN] ê°€ê²Œ ì„ íƒ ì‹¤íŒ¨: {name} // {e}")
            continue

        # ìƒì„¸ì—ì„œ ë¦¬ë·° íƒ­ & ì •ë ¬
        try:
            open_reviews_tab_and_sort(drv, tries=4, sort_latest=sort_latest)
        except Exception as e:
            print(f"[WARN] ë¦¬ë·° íƒ­/ì •ë ¬ ì‹¤íŒ¨: {name} // {e} (ë‹¤ìŒ ê°€ê²Œë¡œ ì§„í–‰)")
            # ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ ê°€ê²Œë¡œ ë„˜ì–´ê°€ë„ë¡ continue
            # ê·¸ë˜ë„ ì´ ê°€ê²Œì˜ ì „ì²´ í˜ì´ì§€/ì„¹ì…˜ ì €ì¥ì€ ì‹œë„
        finally:
            # (ì˜µì…˜) ë”ë³´ê¸° ëª¨ë‘ í¼ì¹˜ê¸°
            if expand_more:
                try:
                    expand_all_reviews(drv, max_clicks=200)
                except Exception as e:
                    print(f"[WARN] ë”ë³´ê¸° í¼ì¹˜ê¸° ì‹¤íŒ¨: {name} // {e}")

        # ì €ì¥ (ê°€ê²Œëª… í¬í•¨)
        safe_name = re.sub(r"[^0-9A-Za-zê°€-í£._-]", "_", name)[:60] or f"place_{idx}"
        drv.switch_to.default_content()
        # save_html(drv, f"{idx:02d}_{safe_name}_fullpage")
        try:
            save_review_section_html(drv, f"{idx:02d}_{safe_name}_reviews")
        except Exception as e:
            print(f"[WARN] ë¦¬ë·° ì„¹ì…˜ ì €ì¥ ì‹¤íŒ¨: {name} // {e}")

        processed += 1

    print(f"\n[DONE] ì´ {processed}ê°œ ê°€ê²Œ ì²˜ë¦¬ ì™„ë£Œ.")
    input("ë¸Œë¼ìš°ì €ëŠ” ì—´ë¦° ìƒíƒœë¡œ ìœ ì§€ë©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ Enter...")

if __name__ == "__main__":
    # ì˜ˆ: ìƒìœ„ 8ê°œ ê°€ê²Œ, ìµœì‹ ìˆœ ì •ë ¬, ë”ë³´ê¸° í¼ì¹˜ê¸° í™œì„±í™”
    run_crawl(max_places=8, sort_latest=True, expand_more=True)
